# Experiment 4C: Framing Effects and Bias Transfer - Clean Results

## Experiment Overview
- **Run Date**: 2025-08-14T14:48:16
- **Mode**: Full
- **Judge Scoring**: Real
- **Score Normalization**: Disabled

## Dataset Summary
- **Total Tokens Analyzed**: 387
- **Positive Sentiment**: 185
- **Negative Sentiment**: 200
- **Neutral Control**: 0
- **Total Score Records**: 100

## Model Analysis
- **Individual Judges**: 10
- **Aggregation Methods**: Naive Average + MLP Aggregator

## Bias Reduction Results

### Framing Bias
- **Individual Judge Mean**: 0.208
- **Naive Average**: 0.059 (71.4% reduction)
- **MLP Aggregator**: 0.331 (-59.7% reduction)

### Frequency Bias
- **Individual Judge Mean**: 0.094
- **Naive Average**: 0.075 (20.3% reduction)
- **MLP Aggregator**: 0.027 (71.4% reduction)

## Key Findings

- MLP increases framing bias by 59.7%
- MLP reduces frequency bias by 71.4%
- Naive averaging reduces framing bias by 71.4%
- Naive averaging reduces frequency bias by 20.3%
- Naive averaging outperforms MLP on framing bias
- MLP outperforms naive averaging on frequency bias

## Files Generated
- **Complete Report**: `20250814_144816_COMPLETE_REPORT.json`
- **Clean Summary**: `20250814_144816_CLEAN_SUMMARY.md`
- **Bias Reduction Plots**: `20250814_144816_bias_reduction_plots.png`

## Interpretation
The bias reduction percentages show how much each aggregation method reduces the cognitive biases present in individual judges:
- **Positive values** = Bias reduction (desirable)
- **Negative values** = Bias amplification (concerning)
- **Comparison**: MLP vs Naive averaging performance
